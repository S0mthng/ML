{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Скачайте датасет MNIST.\n",
        "2. Изучите выборку (какие там картинки, сколько картинок в каждом классе).\n",
        "3. Реализуйте загрузку датасета в память с диска с помощью OpenCV. Использовать готовые реализации датасетов и даталоудеров торча запрещено. Пока можно не заморачиваться многопоточностью.\n",
        "4. Реализуйте аугментацию данных: поворот картинки на определенное кол-во градусов (задается аргументом), зашумление картинки. Реализовывать на numpy. Использовать готовые решения тоже запрещено.\n",
        "5. Реализуйте способ скормить это нейросети (нормализация, приведение к одному разрешению).\n",
        "6. Напишите код нейросети. Использовать Sequential запрещено. Модель пишете руками, наследуясь от torch.nn.Module.\n",
        "7. Реализуйте цикл обучения нейросети. Использовать готовые трейнеры и model.fit() запрещено. Кол-во эпох, learning rate и прочие параметры задаются аргументами.\n",
        "8. Напишите код для инференса и оценки качества работы нейронной сети.\n",
        "9. Оценка качества должна заключаться в подсчете Accuracy, Recall, Precision, F-мера. Пользоваться готовыми решениями тоже запрещено.\n",
        "10. Оформите это как удобную библиотечку, которую можно склонить с гитхаба, положить куда надо файлы весов модели, выборку и обучить / инференсить модель."
      ],
      "metadata": {
        "id": "TR47YfD1uZM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import gzip\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optimizer\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-z7HCFXFZCeY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./MNIST/archive/\"\n",
        "os.makedirs(path, exist_ok = True)\n",
        "sizes = [784, 256, 10]\n",
        "learning_rate = 0.005\n",
        "epochs = 10\n",
        "\n",
        "\n",
        "source = {\"training_images\" : \"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\",\n",
        "          \"training_labels\" : \"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\",\n",
        "          \"test_images\" : \"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\",\n",
        "          \"test_labels\" : \"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"\n",
        "          }"
      ],
      "metadata": {
        "id": "mFVsWvRyDacz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data={}\n",
        "\n",
        "for key in source:\n",
        "  data[key] = source[key].split('/')[-1]\n",
        "  if os.path.exists(path + data[key]):\n",
        "    print(data[key] + \" was here long before you were born...\")\n",
        "  else:\n",
        "    urllib.request.urlretrieve(source[key], path + data[key])\n",
        "    print(data[key] + \" downloaded right now!\")"
      ],
      "metadata": {
        "id": "An3zwtAcDX0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a74858-4218-4a70-e12e-64c255dcd9bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train-images-idx3-ubyte.gz downloaded right now!\n",
            "train-labels-idx1-ubyte.gz downloaded right now!\n",
            "t10k-images-idx3-ubyte.gz downloaded right now!\n",
            "t10k-labels-idx1-ubyte.gz downloaded right now!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {}\n",
        "# Images\n",
        "for key in (\"training_images\", \"test_images\"):\n",
        "  with gzip.open(os.path.join(path, data[key]), \"rb\") as mnist:\n",
        "    dataset[key] = np.frombuffer(mnist.read(), np.uint8, offset = 16).reshape(-1, 28 * 28) / 255\n",
        "    print(\"The shape of {}: {}\".format(key, dataset[key].shape))\n",
        "\n",
        "# Labels\n",
        "for key in (\"training_labels\", \"test_labels\"):\n",
        "  with gzip.open(os.path.join(path, data[key]), \"rb\") as mnist:\n",
        "    dataset[key] = np.frombuffer(mnist.read(), np.uint8, offset = 8)\n",
        "    print(\"The shape of {}: {}\".format(key, dataset[key].shape))\n",
        "\n",
        "\n",
        "#print(dataset[key][0])\n",
        "\n",
        "#Permutation\n",
        "permutation = np.random.permutation(len(dataset[key]))\n",
        "dataset[key] = dataset[key][permutation]\n",
        "\n",
        "#print(permutation)\n",
        "\n",
        "#print(dataset[key][0])\n",
        "\n",
        "x_train, y_train, x_test, y_test = (\n",
        "    dataset[\"training_images\"],\n",
        "    dataset[\"training_labels\"],\n",
        "    dataset[\"test_images\"],\n",
        "    dataset[\"test_labels\"])\n",
        "\n",
        "#print(\"The shape of {}: {}\".format(key, dataset[\"training_images\"].shape))\n",
        "#print(\"The shape of {}: {}\".format(key, dataset[\"training_labels\"].shape))\n",
        "#print(\"The shape of {}: {}\".format(key, dataset[\"test_images\"].shape))\n",
        "#print(\"The shape of {}: {}\".format(key, dataset[\"test_labels\"].shape))"
      ],
      "metadata": {
        "id": "Bg-jFh8MDnjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59b2486-1aac-40c4-dac4-0b620f8c8f0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training_images: (60000, 784)\n",
            "The shape of test_images: (10000, 784)\n",
            "The shape of training_labels: (60000,)\n",
            "The shape of test_labels: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(image):\n",
        "  noise = np.random.normal(0.48, 0.05, image.shape)\n",
        "  gaussedImage = np.clip(image + noise, 0, 1)\n",
        "  return gaussedImage\n",
        "\n",
        "def rotate(image):\n",
        "  angle = np.random.randint(-30, 30)\n",
        "  theta = np.radians(angle)\n",
        "  cos, sin = np.cos(theta), np.sin(theta)\n",
        "  height, width = image.shape\n",
        "  MH, MW = height // 2, width // 2\n",
        "  newImage = np.zeros(height, width)\n",
        "  for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "      x = round((i - MW) * cos + (j - MH) * sin)\n",
        "      y = round( - (i - MW) * sin + (j - MH) * cos)\n",
        "      if (x >= 0 and y >= 0 and x < image.shape[0] and y < image.shape[1]):\n",
        "        newImage[x, y] = image[i, j]\n",
        "  return torch.tensor(newImage)"
      ],
      "metadata": {
        "id": "WB3Nzc6cgHN-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123456\n",
        "gen = np.random.default_rng(seed)\n",
        "learning_rate = 0.005\n",
        "epochs = 10\n",
        "\n",
        "def ReLu(self, x):\n",
        "  return (x >= 0) * x\n",
        "\n",
        "def dReLu(self, x):\n",
        "  return x >= 0\n",
        "\n",
        "def Softmax(self, x):\n",
        "  return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "def dSoftmax(x):\n",
        "  return np.exp(x)/sum(np.exp(x)) * (1 - np.exp(x) / sum (np.exp(x)))\n",
        "\n",
        "\n",
        "parameters = {\n",
        "  'W1': 0.15 * gen.random((784, 256)) - 0.01 * np.sqrt(1 / 256),\n",
        "  'W2': 0.15 * gen.random((256, 10)) - 0.01 * np.sqrt(1 / 10),\n",
        "  'B1': 0.015 * gen.random(256) - 0.001,\n",
        "  'B2': 0.015 * gen.random(10) - 0.001\n",
        "  }\n",
        "\n",
        "def forward(self, x_train):\n",
        "  parameters = self.parameters\n",
        "  parameters['A0'] = x_train\n",
        "  parameters['L1'] = np.dot(parameters['A0'], parameters['W1']) + parameters['B1']\n",
        "  parameters['A1'] = self.ReLu(parameters['L1'])\n",
        "  parameters['D2'] = np.dot(parameters['A1'], parameters['W2']) + parameters['B2']\n",
        "  parameters['A2'] = self.Softmax(parameters['D2'])\n",
        "  return parameters['A2']\n",
        "\n",
        "def backward(self, y_train, output):\n",
        "  parameters = self.parameters\n",
        "\n",
        "  updWeights = {}\n",
        "\n",
        "  error = 2 * (output - y_train) / output.shape[0] * self.dSoftmax(parameters['L2'])\n",
        "  updWeights['W2'] = np.outer(error, parameters['A1'])\n",
        "  updWeights['B2'] = sum(((1 / self.batch) * error), axis = 0)\n",
        "  error = np.dot(parameters['W2'].T, error) * self.dReLu(parameters['L1'])\n",
        "  updWeights['B1'] = sum(np.dot(((1 / self.batch) * error), ['W2'].T) * self.dReLu(parameters['L1'], axis = 0))\n",
        "  updWeights['W1'] = np.outer(error, parameters['A0'])\n",
        "  accuracy += int(np.argmax(output, 1) == np.argmax(y_train, 1))\n",
        "  for key, value in updWeights.items():\n",
        "    self.updWeights[key] -= self.learning_rate * value\n",
        "  return updWeights, accuracy, error\n"
      ],
      "metadata": {
        "id": "22V-Rp8q2jHM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(self, x_train, y_train):\n",
        "  for i in range(epochs):\n",
        "    training_loss = []\n",
        "    training_accuracy = []\n",
        "    loss = 0.0\n",
        "    accuracy = 0\n",
        "    for j in range(len(x_train)):\n",
        "      output = self.forward(x_train)\n",
        "      updWeights, accuracy, loss = self.backward(y_train, output)\n",
        "\n",
        "    training_loss.append(loss)\n",
        "    training_accuracy.append(accuracy)\n",
        "\n",
        "    print(( f\"Epoch: {j}\\n\"\n",
        "            f\"  Training set loss: {loss / len(x_train):.3f}\\n\"\n",
        "            f\"  Training set accuracy: {accuracy / len(x_train)}\"\n",
        "            ))\n",
        "  \n",
        "#def test():\n",
        "#true_positive = np.zeros()\n",
        "#false_positive = np.zeros()\n",
        "#false_negative = np.zeros()\n",
        "\n",
        "#accuracy = correct/ len(labels_dataset)\n",
        "#precision = true_positive / (true_positive + false_positive)\n",
        "#Recall = true_positive / (true_positive + false_negative)\n",
        "#F-Score = 2 * ((precision * recall) / (precision + recall))"
      ],
      "metadata": {
        "id": "7zPfNlJaPk-7"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}